{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in Psychology & Neuroscience (DSPN): \n",
    "\n",
    "## Lecture 12. Data Wrangling (part 2)\n",
    "\n",
    "### Date: October 4, 2022\n",
    "\n",
    "### To-Dos From Last Class:\n",
    "\n",
    "* Download \"imitation inhibition\" task data from <a href=\"https://github.com/hogeveen-lab/DSPN_Fall2022_Git/tree/master/misc_exercises/imitation_inhibition_paradigm\">Github</a>\n",
    "* Download <a href=\"https://github.com/hogeveen-lab/DSPN_Fall2022_Git/tree/master/assignment_starters/assign3_starter\">Assignment #3 starter kit</a>\n",
    "\n",
    "### Today:\n",
    "\n",
    "* Debriefing the leaky integrate-and-fire neuron assignment\n",
    "* Wrangle some real data\n",
    "\n",
    "### Homework\n",
    "* Download <a href=\"https://github.com/hogeveen-lab/DSPN_Fall2022_Git/tree/master/assignment_starters/assign3_starter\">Assignment #3 starter kit</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing gears: Picking up where we left off on Data Wrangling...\n",
    "\n",
    "<img src=\"img/imit_inhib_fileorg.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking into 8 code chunks\n",
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1 --> Importing data wrangling packages I often use\n",
    "import os\n",
    "from glob import glob # only need the glob subpackage from glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting paths to the first level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2 --> setting paths to the first level data\n",
    "\n",
    "# get current working directory\n",
    "base_dir = os.getcwd()\n",
    "# option: base_dir = 'PATH/TO/YOUR/BASEDIR'\n",
    "# Go above current working directory and\n",
    "first_dir = os.path.join(base_dir,'data/first')\n",
    "# option: first_dir = base_dir + '/PATHTO/data/first'\n",
    "P_file_pattern = 'P*.txt'\n",
    "second_dir = os.path.join(base_dir,'data/second')\n",
    "# option: second_dir = base_dir + '/PATHTO/data/second'\n",
    "questionnaire_file = os.path.join(second_dir,'ait_questionnaires.csv')\n",
    "# option: questionnaire_file = base_dir + '/' + second_dir + '/ait_questionnaires.csv'\n",
    "\n",
    "# Using glob to find all participant data files\n",
    "all_files = glob(os.path.join(first_dir,P_file_pattern))\n",
    "# print(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load a test subject to make sense of things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many rows in initial loaded data frame: 521\n",
      "How many rows in key release filtered data frame: 101\n",
      "How many rows in no-double-response filtered data frame: 100\n"
     ]
    }
   ],
   "source": [
    "# Reading in the data\n",
    "sample_df = pd.read_csv(all_files[0], skiprows=5, sep='\\t')\n",
    "print('How many rows in initial loaded data frame:',len(sample_df)) # What things might cause this to not == 100?\n",
    "\n",
    "\n",
    "# Filtering the data down to just the experimental block rows\n",
    "sample_df = sample_df[sample_df['Name.1']==\"AI_Block\"]\n",
    "\n",
    "# Filtering the dataframe down to RELEASES\n",
    "sample_df_releases = sample_df[sample_df['Released']=='Released']\n",
    "\n",
    "# How many key release responses do we have?\n",
    "print('How many rows in key release filtered data frame:',len(sample_df_releases))\n",
    "\n",
    "# Identifying double responses\n",
    "sample_df_releases['shift'] = sample_df_releases['Name.2'].shift(1)\n",
    "# display(sample_df_releases[['Name.2','shift']])\n",
    "\n",
    "# filter down to only the first response\n",
    "sample_df_releases['double_response'] = np.where(sample_df_releases['shift']==sample_df_releases['Name.2'],1,0)\n",
    "double_resp_df = sample_df_releases[sample_df_releases['double_response']==1]\n",
    "# display(double_resp_df[['Name.2','shift','double_response']])\n",
    "\n",
    "# Filtering our double response trials\n",
    "sample_df_releases_nodouble = sample_df_releases[sample_df_releases['double_response']==0] \n",
    "print('How many rows in no-double-response filtered data frame:',len(sample_df_releases_nodouble)) # Seeing if we have the right # of rows now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment / comment lines 1, 2, and 3 to learn a bit more about what a column is within a pandas data frame.\n",
    "\n",
    "# display(sample_df_releases) # 1. data frame\n",
    "# display(sample_df_releases['Finger']) # 2. Series w/in the data frame\n",
    "# display(sample_df_releases['Finger'].values) # 3. pull the values from a DataFrame.series, returns an array!\n",
    "\n",
    "# Note: within each data frame column exists a series, \n",
    "# which is just a special / pandas-y way of storing arrays. Numpy likes to keep things in array form like the below...\n",
    "# np.array([1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1,\n",
    "# #        2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1,\n",
    "# #        1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2,\n",
    "# #        2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1,\n",
    "# #        2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Iterate through to load the first level data\n",
    "###    * Concatenate all together to create one data frame to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge with questionnaire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write to trial-level allsubjects csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick up next class..\n",
    "7. Compute summary measures\n",
    "8. Save to summary allsubjects csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
